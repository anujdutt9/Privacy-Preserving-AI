{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-1: Create a Dummy Database\n",
    "\n",
    "Here, we create a dummy database consisting of 5000 values representing 0's and 1's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0,  ..., 1, 1, 0], dtype=torch.int32)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Dependencies\n",
    "import torch\n",
    "\n",
    "# Set seed for reproducability\n",
    "torch.manual_seed(101)\n",
    "\n",
    "# Number of values in our Database\n",
    "num_values = 5000\n",
    "\n",
    "# Create the Database where '1' represents a value > 0.5 and '0' otherwise\n",
    "db = torch.rand(num_values)\n",
    "db = (db > 0.5).int()\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5000])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-2: Generate Parallel Databases\n",
    "\n",
    "Let us say we have a database with random 5000 values containing 0's and 1's in it. Now, if we remove one value at random from this database and copy thi leftover database with 4999 values, we now have a parallel database with 4999 values each.\n",
    "\n",
    "If we repeat this process 5000 times, we get 5000 parallel databases with 4999 values each, i.e. one value missing at every incremental location in each database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 1, 0], dtype=torch.int32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's take the first 5 values fromt the Database\n",
    "db[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1, 0, 0], dtype=torch.int32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let us say we want to remove the value at 2nd index\n",
    "remove_idx = 2\n",
    "\n",
    "# Hence the above 5 values change to the following after removing the\n",
    "# value at 2nd index\n",
    "# db[0:2] => takes values at idx 0 and 1\n",
    "# db[3:] => takes values from idx 3 till the end\n",
    "torch.cat((db[0:2], db[3:]))[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, we can generalize the above term as follows:\n",
    "\n",
    "Given the index to remove the value from the Database, we can define the remaining Database as follows:\n",
    "\n",
    "**torch.cat((db[0:remove_idx], db[remove_idx+1:]))**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to Create Parallel Databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Create Parallel Databases\n",
    "def get_parallel_db(db, remove_idx):\n",
    "    return torch.cat((db[0:remove_idx], db[remove_idx+1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1, 0, 0], dtype=torch.int32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the function\n",
    "# Remove the first value from the database\n",
    "get_parallel_db(db, 0)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4999])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the Shape of the new Database\n",
    "get_parallel_db(db, 0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get Parallel Databases\n",
    "def get_parallel_dbs(db):\n",
    "    # List to contain Parallel Databases\n",
    "    parallel_dbs = list()\n",
    "    \n",
    "    # Iterate over all values in the Database to create new Databases\n",
    "    for i in range(db.numpy().shape[0]):\n",
    "        parallel_dbs.append(get_parallel_db(db, i))\n",
    "    \n",
    "    return parallel_dbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all Parallel Databases\n",
    "pdbs = get_parallel_dbs(db)\n",
    "len(pdbs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning up the code and Writing the Functions in a Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class createDatabase:\n",
    "    # Init Function\n",
    "    def __init__(self, num_values):\n",
    "        self.num_values = num_values\n",
    "        \n",
    "    # Function to Create Parallel Databases by removin an element\n",
    "    def get_parallel_db(self, db, remove_idx):\n",
    "        return torch.cat((self.db[0:self.remove_idx], self.db[self.remove_idx+1:]))\n",
    "    \n",
    "    # Function to get list of Parallel Databases\n",
    "    def get_parallel_dbs(self, db):\n",
    "        # List to contain Parallel Databases\n",
    "        parallel_dbs = list()\n",
    "        # Iterate over all values in the Database to create new Databases\n",
    "        for i in range(self.db.numpy().shape[0]):\n",
    "            parallel_dbs.append(get_parallel_db(self.db, i))\n",
    "        return parallel_dbs\n",
    "\n",
    "    # Function to Create Parallel Databases\n",
    "    def create_db_and_parallels(self):\n",
    "        # Create a new Database\n",
    "        db = db = torch.rand(self.num_values)\n",
    "        db = (db > 0.5).int()\n",
    "        # Get all Parallel Databases\n",
    "        pdbs = get_parallel_dbs(db)\n",
    "        return db, pdbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Database with Parallel Database\n",
    "database = createDatabase(20)\n",
    "db, pdbs = database.create_db_and_parallels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1],\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the sample database\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1],\n",
       "        dtype=torch.int32),\n",
       " tensor([0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1],\n",
       "        dtype=torch.int32),\n",
       " tensor([0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1],\n",
       "        dtype=torch.int32),\n",
       " tensor([0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1],\n",
       "        dtype=torch.int32),\n",
       " tensor([0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1],\n",
       "        dtype=torch.int32),\n",
       " tensor([0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1],\n",
       "        dtype=torch.int32),\n",
       " tensor([0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1],\n",
       "        dtype=torch.int32),\n",
       " tensor([0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1],\n",
       "        dtype=torch.int32),\n",
       " tensor([0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1],\n",
       "        dtype=torch.int32),\n",
       " tensor([0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1],\n",
       "        dtype=torch.int32),\n",
       " tensor([0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1],\n",
       "        dtype=torch.int32),\n",
       " tensor([0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1],\n",
       "        dtype=torch.int32),\n",
       " tensor([0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1],\n",
       "        dtype=torch.int32),\n",
       " tensor([0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1],\n",
       "        dtype=torch.int32),\n",
       " tensor([0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1],\n",
       "        dtype=torch.int32),\n",
       " tensor([0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1],\n",
       "        dtype=torch.int32),\n",
       " tensor([0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1],\n",
       "        dtype=torch.int32),\n",
       " tensor([0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1],\n",
       "        dtype=torch.int32),\n",
       " tensor([0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1],\n",
       "        dtype=torch.int32),\n",
       " tensor([0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0],\n",
       "        dtype=torch.int32)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the sample parallel databases\n",
    "pdbs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-3: Evaluate the Differential Privacy of a Funtion\n",
    "\n",
    "We want to be able to query our database and evaluate that whether or not the result of the query is leaking \"private\" information. This is about evaluating that whether the output of a query changes when we remove someone from the database. If the output changes, that means it has learn the private information about the user that was removed. If the output does not change after removing the person, then it has not learn any private information.\n",
    "Specifically, we want to evaluate the maximum amount the query changes when someone is removed. So, in order to evaluate how much privacy is leaked, we are going to iterate over each person in the database and measure the difference in the output of the query relative to when we query the entire database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Query the Database\n",
    "def query(db):\n",
    "    return db.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1],\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(12)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query Output on Original Database\n",
    "query(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database: 0\t Query Output: 12\n",
      "\n",
      "Database: 1\t Query Output: 11\n",
      "\n",
      "Database: 2\t Query Output: 12\n",
      "\n",
      "Database: 3\t Query Output: 12\n",
      "\n",
      "Database: 4\t Query Output: 12\n",
      "\n",
      "Database: 5\t Query Output: 11\n",
      "\n",
      "Database: 6\t Query Output: 12\n",
      "\n",
      "Database: 7\t Query Output: 11\n",
      "\n",
      "Database: 8\t Query Output: 11\n",
      "\n",
      "Database: 9\t Query Output: 11\n",
      "\n",
      "Database: 10\t Query Output: 11\n",
      "\n",
      "Database: 11\t Query Output: 12\n",
      "\n",
      "Database: 12\t Query Output: 11\n",
      "\n",
      "Database: 13\t Query Output: 11\n",
      "\n",
      "Database: 14\t Query Output: 11\n",
      "\n",
      "Database: 15\t Query Output: 11\n",
      "\n",
      "Database: 16\t Query Output: 12\n",
      "\n",
      "Database: 17\t Query Output: 11\n",
      "\n",
      "Database: 18\t Query Output: 12\n",
      "\n",
      "Database: 19\t Query Output: 11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the Query on the Parallel Database Values\n",
    "for i in range(len(pdbs)):\n",
    "    print(\"Database: {0}\\t Query Output: {1}\\n\".format(i, query(pdbs[i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, what do we see from above? We see that when we remove people from the original database \"db\", it changes the ouptut of the \"query[pdbs]\". This means that the output of the query is conditioned directly on the information of a lot of people in this database due to which when we run the query on the parallel database (with someone removed), the ouptut of the query changes as compared to the ouptut of query for the original database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see how much the query for paralel database deviate from\n",
    "# that of the original database\n",
    "\n",
    "# Query Output for Original Database\n",
    "full_db_result = query(db)\n",
    "\n",
    "# Variable to store the max_deviation\n",
    "sensitivity = 0\n",
    "\n",
    "# Query Output for Parallel Databases\n",
    "for pdb in pdbs:\n",
    "    pdb_result = query(pdb)\n",
    "    \n",
    "    # Find deviation in outputs using L1 Norm\n",
    "    db_distance = torch.abs(pdb_result - full_db_result)\n",
    "    \n",
    "    # Get the maximum deviation/distance\n",
    "    if (db_distance > sensitivity):\n",
    "        sensitivity = db_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Maximum Deviation/Sensitivity/L1 Sensitivity\n",
    "# Sensitivity: The max amount that the query changes when removing an individual from the database\n",
    "sensitivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a very important result from above. Since, our database contains binary values, the most that any value can change is = 1 - 0 => 1. This is provde by the value of the \"max_distance\" above. This also holds true if we have 5000 values instead of just 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sensitivity Function\n",
    "def sensitivity(query, n_entries=1000):\n",
    "    # Create the Database and Iitialize all Parallel Databases\n",
    "    database = createDatabase(n_entries)\n",
    "    db, pdbs = database.create_db_and_parallels()\n",
    "\n",
    "    # Sensitivity\n",
    "    max_distance = 0\n",
    "    \n",
    "    # Query Output for Original Database\n",
    "    full_db_result = query(db)\n",
    "    \n",
    "    # Calculate Sensitivity\n",
    "    for pdb in pdbs:\n",
    "        pdb_result = query(pdb)\n",
    "    \n",
    "        # Find deviation in outputs using L1 Norm\n",
    "        db_distance = torch.abs(pdb_result - full_db_result)\n",
    "\n",
    "        # Get the maximum deviation/distance\n",
    "        if (db_distance > max_distance):\n",
    "            max_distance = db_distance\n",
    "    \n",
    "    return max_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Query\n",
    "def query(db):\n",
    "    return db.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the Function\n",
    "sensitivity(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Another Query\n",
    "def query(db):\n",
    "    return db.float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0005)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the Function\n",
    "sensitivity(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L1 Sensitivity for Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold Sensitivity Query\n",
    "def query(db, threshold=5):\n",
    "    return (db.sum() > threshold).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "tensor(1.)\n",
      "0\n",
      "tensor(1.)\n",
      "0\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Create and Query 10 databases 10 times\n",
    "for i in range(10):\n",
    "    print(sensitivity(query, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-4: Performing a Differencing Attack on the Database\n",
    "\n",
    "**Aim:** \n",
    "\n",
    "Construct a database and then demonstrate that how wer can use two different sum queries to expose the value of the person represented by the row 10 in the database.\n",
    "\n",
    "This attack works as follows:\n",
    "\n",
    "1. If we have a base database, say, the original database.\n",
    "2. We can get a parallel database by removing one person from the original database.\n",
    "3. Then, if we take the difference between the sum of two databases, we can figure out the missing person.\n",
    "4. We can also use make the Differencing Attack using the mean as well as the threshold values.\n",
    "\n",
    "Example:\n",
    "\n",
    "1. SELECT count(*) from my_cancer_database;\n",
    "2. SELECT count(*) from my_cacer_database WHERE person_name!=\"john doe\";\n",
    "\n",
    "By comparing the above two SQL queries, we can know if john doe had cancer or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Database with 10 rows\n",
    "# Create the Database and Iitialize all Parallel Databases\n",
    "database = createDatabase(100)\n",
    "db, _ = database.create_db_and_parallels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "        1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1,\n",
       "        1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1,\n",
       "        1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0], dtype=torch.int32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Original Database\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "        0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1,\n",
       "        1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "        1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0], dtype=torch.int32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove Index 10 from Parallel Database\n",
    "pdb = get_parallel_db(db, remove_idx= 10)\n",
    "pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0, dtype=torch.int32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Original Value\n",
    "db[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0, dtype=torch.int32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Differencing Attack using Sum Query\n",
    "sum(db) - sum(pdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0, dtype=torch.int32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Differencing Attack using Mean Query\n",
    "(sum(db) / len(db)) - (sum(pdb) / len(pdb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Differencing Attack using Threshold Query\n",
    "(sum(db) > 49).float() - (sum(pdb) > 49).float()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
